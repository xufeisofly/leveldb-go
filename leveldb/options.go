package leveldb

type Env struct{}
type Logger struct{}
type BlockCache struct{}
type FilterPolicy struct{}

type Options struct {
	Comparator Comparator
	// If true, the database will be created if it is missing
	CreateIfMissing bool
	// If true, an error is raised if database already exsits
	ErrorIfExsits bool
	// If true, the implementation will do aggressive checking of the
	// data it is processing and will stop early if it detects any
	// errors.  This may have unforeseen ramifications: for example, a
	// corruption of one DB entry may cause a large number of entries to
	// become unreadable or for the entire DB to become unopenable.
	ParanoidChecks bool
	// Use the specified object to interact with the environment,
	// e.g. to read/write files, schedule background work, etc.
	// Default: Env::Default()
	Env *Env
	// Any internal progress/error information generated by the db will
	// be written to info_log if it is non-null, or to a file stored
	// in the same directory as the DB contents if info_log is null.
	InfoLog *Logger

	// -------------------
	// Parameters that affect performance

	// Amount of data to build up in memory (backed by an unsorted log
	// on disk) before converting to a sorted on-disk file.
	//
	// Larger values increase performance, especially during bulk loads.
	// Up to two write buffers may be held in memory at the same time,
	// so you may wish to adjust this parameter to control memory usage.
	// Also, a larger write buffer will result in a longer recovery time
	// the next time the database is opened.
	WriteBufferSize uint64
	// Number of open files that can be used by the DB.  You may need to
	// increase this if your database has a large working set (budget
	// one open file per 2MB of working set).
	MaxOpenFiles int
	// Control over blocks (user data is stored in a set of blocks, and
	// a block is the unit of reading from disk).
	// If non-null, use the specified cache for blocks.
	// If null, leveldb will automatically create and use an 8MB internal cache.
	Cache *BlockCache
	// Approximate size of user data packed per block.  Note that the
	// block size specified here corresponds to uncompressed data.  The
	// actual size of the unit read from disk may be smaller if
	// compression is enabled.  This parameter can be changed dynamically.
	BlockSize uint64
	// Number of keys between restart points for delta encoding of keys.
	// This parameter can be changed dynamically.  Most clients should
	// leave this parameter alone.
	BlockRestartInternal int
	// Leveldb will write up to this amount of bytes to a file before
	// switching to a new one.
	// Most clients should leave this parameter alone.  However if your
	// filesystem is more efficient with larger files, you could
	// consider increasing the value.  The downside will be longer
	// compactions and hence longer latency/performance hiccups.
	// Another reason to increase this parameter might be when you are
	// initially populating a large database.
	MaxFileSize uint64
	// Compress blocks using the specified compression algorithm.  This
	// parameter can be changed dynamically.
	//
	// Default: kSnappyCompression, which gives lightweight but fast
	// compression.
	//
	// Typical speeds of kSnappyCompression on an Intel(R) Core(TM)2 2.4GHz:
	//    ~200-500MB/s compression
	//    ~400-800MB/s decompression
	// Note that these speeds are significantly faster than most
	// persistent storage speeds, and therefore it is typically never
	// worth switching to kNoCompression.  Even if the input data is
	// incompressible, the kSnappyCompression implementation will
	// efficiently detect that and will switch to uncompressed mode.
	Compression CompressionType
	// Compression level for zstd.
	// Currently only the range [-5,22] is supported. Default is 1.
	ZstdCompressionLevel int
	// EXPERIMENTAL: If true, append to existing MANIFEST and log files
	// when a database is opened.  This can significantly speed up open.
	//
	// Default: currently false, but may become true later.
	ReuseLogs bool
	// If non-null, use the specified filter policy to reduce disk reads.
	// Many applications will benefit from passing the result of
	// NewBloomFilterPolicy() here.
	FilterPolicy *FilterPolicy
}

var DefaultOptions = &Options{
	Comparator:      NewBytewiseComparator(),
	CreateIfMissing: false,
	ErrorIfExsits:   false,
	ParanoidChecks:  false,
	Env:             &Env{},
}
